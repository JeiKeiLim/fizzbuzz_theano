{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fizzbuzz for theano Ver 0.9.1\n",
    "Author : Jongkuk Lim (Lim.JeiKei@gmail.com)<br />\n",
    "Date : 2016. 06. 23<br />\n",
    "Last update : 2016. 06. 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries including Multi Layer Perceptron\n",
    "You can find MLP script from http://deeplearning.net/tutorial/mlp.html<br />\n",
    "However, I modified only its activation function to ReLU which shows promising result in general.<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from mlp import MLP, HiddenLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions\n",
    "I had too much fun from this project so ended up, I made functions which really don't need<br />\n",
    "But it's fun to look at it anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_decode(b_data):\n",
    "    result = 0\n",
    "    for i in range(len(b_data)):\n",
    "        result += (b_data[i]*(2**i))\n",
    "    return result.astype('int64')\n",
    "    \n",
    "def binary_encode(i, num_digits):\n",
    "    return np.array([i >> d & 1 for d in range(num_digits)])\n",
    "\n",
    "def fizz_buzz_encode_num(i):\n",
    "    if   i % 15 == 0: return 3\n",
    "    elif i % 5  == 0: return 2\n",
    "    elif i % 3  == 0: return 1\n",
    "    else:             return 0\n",
    "\n",
    "def fizz_buzz_encode(i):\n",
    "    fizz_buzz = fizz_buzz_encode_num(i)\n",
    "    result = np.array([0, 0, 0, 0])\n",
    "    result[fizz_buzz] = 1\n",
    "    return result\n",
    "\n",
    "def fizz_buzz_encode_str(i):\n",
    "    fizz_buzz = fizz_buzz_encode_num(i)\n",
    "    fizz_str = [str(i), 'fizz', 'buzz', 'fizzbuzz']\n",
    "    return fizz_str[fizz_buzz]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining experiment constants\n",
    "<B>NUM_DIGITS</B> decides how big your number will be and the number of input neuron.<br />\n",
    "<B>NUM_HIDDEN</B> will be the number of hidden node for MLP<br />\n",
    "<B>batch_size</B> is the number to split training set into batch_size when the data is too big, this will be helpful.<br />\n",
    "<B>learning_rate</B> decides whether the classifier will learn fast or not. It's bad idea to put too big number in learning rate however.<br />\n",
    "<B>L1</B> and <B>L2</B> regularizer is used for training and regularizing its error cost.<br />\n",
    "<B>n_test</B> is the number of testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_DIGITS = 10\n",
    "NUM_HIDDEN = 1000\n",
    "\n",
    "batch_size = 128\n",
    "learning_rate = 0.01\n",
    "L1_reg = 0.00\n",
    "L2_reg = 0.0001\n",
    "\n",
    "n_test = int((2**NUM_DIGITS)*0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = np.array([binary_encode(i, NUM_DIGITS)     for i in range(n_test+1, 2 ** NUM_DIGITS)]).astype('float64')\n",
    "train_y = np.array([fizz_buzz_encode_num(i)          for i in range(n_test+1, 2 ** NUM_DIGITS)]).astype('int32')\n",
    "\n",
    "test_x = np.array([binary_encode(i, NUM_DIGITS)      for i in range(1, n_test)]).astype('float64')\n",
    "test_y = np.array([fizz_buzz_encode_num(i)           for i in range(1, n_test)]).astype('int32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training and testing set onto VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_x = theano.shared(train_x)\n",
    "tr_y = theano.shared(train_y)\n",
    "te_x = theano.shared(test_x)\n",
    "te_y = theano.shared(test_y)\n",
    "\n",
    "n_train_batches = tr_x.get_value(borrow=True).shape[0] // batch_size\n",
    "\n",
    "index = T.lscalar()\n",
    "x = T.matrix('x')\n",
    "y = T.ivector('y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1234)\n",
    "classifier = MLP(\n",
    "    rng=rng,\n",
    "    input=x,\n",
    "    n_in=NUM_DIGITS,\n",
    "    n_hidden=NUM_HIDDEN,\n",
    "    n_out=4\n",
    ")\n",
    "\n",
    "cost = (classifier.negative_log_likelihood(y) \n",
    "       + L1_reg * classifier.L1\n",
    "       + L2_reg * classifier.L2_sqr)\n",
    "\n",
    "test_model = theano.function(\n",
    "    inputs=[],\n",
    "    outputs=classifier.errors(y),\n",
    "    givens={\n",
    "        x:te_x,\n",
    "        y:te_y\n",
    "    }\n",
    ")\n",
    "\n",
    "gparams = [T.grad(cost, param) for param in classifier.params]\n",
    "updates = [\n",
    "    (param, param - learning_rate * gparam) for param, gparam in zip(classifier.params, gparams)\n",
    "]\n",
    "\n",
    "train_model = theano.function(\n",
    "    inputs=[index],\n",
    "    outputs=cost,\n",
    "    updates=updates,\n",
    "    givens={\n",
    "        x: tr_x[index * batch_size : (index+1) * batch_size],\n",
    "        y: tr_y[index * batch_size : (index+1) * batch_size]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Since we do not have validation set which quite often exist in deep learning session, <br />\n",
    "Training will stop when either testing error is zero or training improvement is lower than stop error we set.<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter : 0, Average batch cost : 1.3026650799, Test Error : 46.5346534653%\n",
      "Iter : 1000, Average batch cost : 1.09654459226, Test Error : 46.5346534653%\n",
      "Iter : 2000, Average batch cost : 0.855938997098, Test Error : 31.6831683168%\n",
      "Iter : 3000, Average batch cost : 0.538681292742, Test Error : 21.7821782178%\n",
      "Iter : 4000, Average batch cost : 0.335487942766, Test Error : 4.9504950495%\n",
      "Iter : 5000, Average batch cost : 0.233976688532, Test Error : 0.990099009901%\n",
      "Iter : 6000, Average batch cost : 0.183929424596, Test Error : 0.0%\n",
      "Your training is over.\n"
     ]
    }
   ],
   "source": [
    "def print_status(n_iter, minibatch_avg_cst, test_err):\n",
    "    print(\"Iter : \", n_iter, \", Average batch cost : \" , minibatch_avg_cst, \", Test Error : \", str(test_err*100), \"%\", sep=\"\")\n",
    "\n",
    "best_loss = np.inf\n",
    "prev_minibatch_avg_cst = np.inf\n",
    "minibatch_avg_cst = np.inf\n",
    "\n",
    "validate_freq = 1000\n",
    "max_epoch = 50000\n",
    "\n",
    "stop_err = 0.001\n",
    "\n",
    "for i in range(max_epoch):\n",
    "    minibatch_avg_cst = []\n",
    "    \n",
    "    for minibatch_index in range(n_train_batches):\n",
    "        minibatch_avg_cst.append( train_model(minibatch_index) )\n",
    "    \n",
    "    minibatch_avg_cst = np.mean(minibatch_avg_cst)\n",
    "    \n",
    "    if i%validate_freq == 0:\n",
    "        test_err = test_model()\n",
    "        \n",
    "        if test_err < best_loss:\n",
    "            best_loss = test_err\n",
    "            \n",
    "        if prev_minibatch_avg_cst-minibatch_avg_cst < stop_err or test_err == 0.0:\n",
    "            break\n",
    "        \n",
    "        prev_minibatch_avg_cst = minibatch_avg_cst\n",
    "            \n",
    "        print_status(i, minibatch_avg_cst, test_err)\n",
    "        \n",
    "print_status(i, minibatch_avg_cst, test_model())\n",
    "print('Your training is over.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a model to check how the testing result came out\n",
    "Test model only shows its error rate.<br />\n",
    "However, we need to see what its answer was in order to analyze the model from time to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check_y_model = theano.function(\n",
    "    inputs=[],\n",
    "    outputs=classifier.logRegressionLayer.y_pred,\n",
    "    givens={\n",
    "        x:te_x\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking which data was failed to classify\n",
    "If test error is zero, it will just show every data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : .,., isDiff :False\n",
      "2 : .,., isDiff :False\n",
      "3 : fizz,fizz, isDiff :False\n",
      "4 : .,., isDiff :False\n",
      "5 : buzz,buzz, isDiff :False\n",
      "6 : fizz,fizz, isDiff :False\n",
      "7 : .,., isDiff :False\n",
      "8 : .,., isDiff :False\n",
      "9 : fizz,fizz, isDiff :False\n",
      "10 : buzz,buzz, isDiff :False\n",
      "11 : .,., isDiff :False\n",
      "12 : fizz,fizz, isDiff :False\n",
      "13 : .,., isDiff :False\n",
      "14 : .,., isDiff :False\n",
      "15 : fizzbuzz,fizzbuzz, isDiff :False\n",
      "16 : .,., isDiff :False\n",
      "17 : .,., isDiff :False\n",
      "18 : fizz,fizz, isDiff :False\n",
      "19 : .,., isDiff :False\n",
      "20 : buzz,buzz, isDiff :False\n",
      "21 : fizz,fizz, isDiff :False\n",
      "22 : .,., isDiff :False\n",
      "23 : .,., isDiff :False\n",
      "24 : fizz,fizz, isDiff :False\n",
      "25 : buzz,buzz, isDiff :False\n",
      "26 : .,., isDiff :False\n",
      "27 : fizz,fizz, isDiff :False\n",
      "28 : .,., isDiff :False\n",
      "29 : .,., isDiff :False\n",
      "30 : fizzbuzz,fizzbuzz, isDiff :False\n",
      "31 : .,., isDiff :False\n",
      "32 : .,., isDiff :False\n",
      "33 : fizz,fizz, isDiff :False\n",
      "34 : .,., isDiff :False\n",
      "35 : buzz,buzz, isDiff :False\n",
      "36 : fizz,fizz, isDiff :False\n",
      "37 : .,., isDiff :False\n",
      "38 : .,., isDiff :False\n",
      "39 : fizz,fizz, isDiff :False\n",
      "40 : buzz,buzz, isDiff :False\n",
      "41 : .,., isDiff :False\n",
      "42 : fizz,fizz, isDiff :False\n",
      "43 : .,., isDiff :False\n",
      "44 : .,., isDiff :False\n",
      "45 : fizzbuzz,fizzbuzz, isDiff :False\n",
      "46 : .,., isDiff :False\n",
      "47 : .,., isDiff :False\n",
      "48 : fizz,fizz, isDiff :False\n",
      "49 : .,., isDiff :False\n",
      "50 : buzz,buzz, isDiff :False\n",
      "51 : fizz,fizz, isDiff :False\n",
      "52 : .,., isDiff :False\n",
      "53 : .,., isDiff :False\n",
      "54 : fizz,fizz, isDiff :False\n",
      "55 : buzz,buzz, isDiff :False\n",
      "56 : .,., isDiff :False\n",
      "57 : fizz,fizz, isDiff :False\n",
      "58 : .,., isDiff :False\n",
      "59 : .,., isDiff :False\n",
      "60 : fizzbuzz,fizzbuzz, isDiff :False\n",
      "61 : .,., isDiff :False\n",
      "62 : .,., isDiff :False\n",
      "63 : fizz,fizz, isDiff :False\n",
      "64 : .,., isDiff :False\n",
      "65 : buzz,buzz, isDiff :False\n",
      "66 : fizz,fizz, isDiff :False\n",
      "67 : .,., isDiff :False\n",
      "68 : .,., isDiff :False\n",
      "69 : fizz,fizz, isDiff :False\n",
      "70 : buzz,buzz, isDiff :False\n",
      "71 : .,., isDiff :False\n",
      "72 : fizz,fizz, isDiff :False\n",
      "73 : .,., isDiff :False\n",
      "74 : .,., isDiff :False\n",
      "75 : fizzbuzz,fizzbuzz, isDiff :False\n",
      "76 : .,., isDiff :False\n",
      "77 : .,., isDiff :False\n",
      "78 : fizz,fizz, isDiff :False\n",
      "79 : .,., isDiff :False\n",
      "80 : buzz,buzz, isDiff :False\n",
      "81 : fizz,fizz, isDiff :False\n",
      "82 : .,., isDiff :False\n",
      "83 : .,., isDiff :False\n",
      "84 : fizz,fizz, isDiff :False\n",
      "85 : buzz,buzz, isDiff :False\n",
      "86 : .,., isDiff :False\n",
      "87 : fizz,fizz, isDiff :False\n",
      "88 : .,., isDiff :False\n",
      "89 : .,., isDiff :False\n",
      "90 : fizzbuzz,fizzbuzz, isDiff :False\n",
      "91 : .,., isDiff :False\n",
      "92 : .,., isDiff :False\n",
      "93 : fizz,fizz, isDiff :False\n",
      "94 : .,., isDiff :False\n",
      "95 : buzz,buzz, isDiff :False\n",
      "96 : fizz,fizz, isDiff :False\n",
      "97 : .,., isDiff :False\n",
      "98 : .,., isDiff :False\n",
      "99 : fizz,fizz, isDiff :False\n",
      "100 : buzz,buzz, isDiff :False\n",
      "101 : .,., isDiff :False\n"
     ]
    }
   ],
   "source": [
    "y_from_model = check_y_model()\n",
    "\n",
    "for i,j,k in zip(test_x, test_y, y_from_model):\n",
    "    fizz_str = [str(binary_decode(i)), 'fizz', 'buzz', 'fizzbuzz']\n",
    "    \n",
    "    if test_err == 0:\n",
    "        print(binary_decode(i), \" : \", fizz_str[j], \",\", fizz_str[k], ', isDiff :', (j!=k), sep=\"\")\n",
    "    elif j != k:\n",
    "        print(binary_decode(i), \" : \", fizz_str[j], \",\", fizz_str[k], ', isDiff :', (j!=k), sep=\"\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
